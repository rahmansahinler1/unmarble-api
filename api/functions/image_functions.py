from PIL import Image
from google import genai
from google.genai import types
from dotenv import load_dotenv
import io
import os

class ImageFunctions:
    def __init__(self):
        load_dotenv()
        self.client = genai.Client(
            api_key=os.getenv("GEMINI_API_KEY"),
        )
        self.model = "gemini-2.5-flash-image"
        self.max_preview_size = (400, 500)

    def create_preview(self, image_bytes):
        image = Image.open(io.BytesIO(image_bytes))
        image.thumbnail(self.max_preview_size, Image.LANCZOS)
        output = io.BytesIO()
        image.save(output, format='WEBP', quality=100, method=6)
        return output.getvalue()

    def generate_image(self, yourself_image_base64, clothing_image_base64):
        main_prompt = f"""
        Combine two images seamlessly. In the first image, there is a person.
        In the second image, there is a clothing item which may or may not be worn by a model.
        Extract the clothing item from the second image (if it is worn by a model, remove the model completely and keep only the clothing).
        Place the clothing naturally on the person in the first image, preserving body proportions, posture, and all human features exactly as in the original.
        Never modify or stylize the personâ€™s face or body.
        Only adjust lighting and shadows to make the combination realistic.
        The final result must look like the person in the first image is realistically wearing the clothing from the second image.
        Be careful with the preserving hidden body parts in the first image.
        Be careful with the preserving the body-logic when new clothing is dressed, you can change to show legs if clothing is shorts for example.
        """

        # Create parts list using Blob format (matching sample code)
        person_part = types.Part(
            inline_data=types.Blob(
                data=yourself_image_base64,
                mime_type="image/jpeg"
            )
        )
        clothing_part = types.Part(
            inline_data=types.Blob(
                data=clothing_image_base64,
                mime_type="image/jpeg"
            )
        )
        text_part = types.Part.from_text(text=main_prompt)

        # Contents is a list of Parts (not wrapped in Content object)
        contents = [person_part, clothing_part, text_part]

        # Configure model response to include IMAGE output
        generate_config = types.GenerateContentConfig(
            response_modalities=["IMAGE"],
            temperature=0.2
        )

        # Send to model
        response = self.client.models.generate_content(
            model=self.model,
            contents=contents,
            config=generate_config,
        )

        # Extract the generated image
        if not response.candidates:
            raise RuntimeError("No image generated by model.")

        image_part = response.candidates[0].content.parts[0]
        return image_part.inline_data.data
